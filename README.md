![header](https://capsule-render.vercel.app/api?type=rect&height=100&section=header&color=gradient&text=üëã%20Daekeun%20Kim%20(ÍπÄÎåÄÍ∑º,%20ÈáëÂûàÊßø)&fontSize=36)

With 22 years of experience, including 19 years specializing in AI/ML, Daekeun has worked across startups, manufacturing, FSI, and cloud, gaining deep expertise in developing and deploying AI/ML products. Daekeun holds 6 first-author patents and have led AI/ML projects that contributed to the mass production of over 20 products.

As an AI/ML technical specialist, Daekeun has led over 150+ AI/ML workloads, delivered 80+ seminars as the ML community tech leader, and mentored 18 ML experts. While his career was deeply rooted in computer vision, his expertise now spans all AI/ML domains, including GenAI, with a strong focus SLM fine-tuning and SLM/LLM serving. Daekeun has a double major in computer science and mathematics, and a master‚Äôs in computer science specialized in ML.

[![LinkedIn Badge](https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&style=for-the-badge&logoColor=fff&link=https://www.linkedin.com/in/daekeun-kim)](https://www.linkedin.com/in/daekeun-kim) [![HuggingFace Badge](http://img.shields.io/badge/-HuggingFace-343839?style=for-the-badge&logo=huggingface&link=https://huggingface.co/daekeun-ml)](https://huggingface.co/daekeun-ml) [![GitBook Badge](https://img.shields.io/badge/GitBook-3884FF?style=for-the-badge&logo=gitbook&logoColor=fff&link=https://housekdk.gitbook.io)](https://housekdk.gitbook.io)

[![Daekeun's GitHub stats](https://github-readme-stats.vercel.app/api?username=daekeun-ml&theme=solarized-light&hide_rank=true)](https://github.com/daekeun-ml/github-readme-stats) ![Top Langs](https://github-readme-stats.vercel.app/api/top-langs/?username=daekeun-ml&layout=compact&custom_title=My&nbsp;Language&nbsp;)

---

## üß† Areas of Expertise

- üßë‚Äçüíª **Modeling & Deployment**: SLM/LLM fine-tuning, model serving, evaluation-driven LLMOps, Traditional ML/Data Science, Computer Vision
- ‚òÅÔ∏è **Cloud ML Platforms**: Amazon SageMaker, Azure ML, Hugging Face
- üìö **Research to Production**: 6 academic papers, 6 1st author patents, 20+ produductions, 2 tech book translations
- üé§ **Thought Leadership**: 80+ seminars, 40+ public talks, 18 ML mentees

---

## üìù Tech Blog Contributions

- **Daekeun Kim** (2024). [Fine-tune/Evaluate/Quantize SLM/LLM using the torchtune on Azure ML. Microsoft Tech Community.](https://techcommunity.microsoft.com/blog/machinelearningblog/fine-tuneevaluatequantize-slmllm-using-the-torchtune-on-azure-ml/4285663)
- **Daekeun Kim** (2024). [Generate Synthetic QnAs from Real-world Data on Azure. Microsoft Tech Community.](https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/generate-synthetic-qnas-from-real-world-data-on-azure/ba-p/4202053)
- **Daekeun Kim** (2024). [Fine-tuning Florence-2 for VQA (Visual Question Answering) using the Azure ML Python SDK and MLflow. Microsoft Tech Community.](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/fine-tuning-florence-2-for-vqa-visual-question-answering-using/ba-p/4181123)
- Manoranjan Rajguru and **Daekeun Kim** (2024). [Fine-tune Small Language Model (SLM) Phi-3 using Azure Machine Learning. Microsoft Tech Community.](https://techcommunity.microsoft.com/t5/ai-machine-learning-blog/finetune-small-language-model-slm-phi-3-using-azure-machine/ba-p/4130399)
- **Daekeun Kim** (2023). [Quickly build high-accuracy Generative AI applications on enterprise data using Amazon Kendra, LangChain, and LLMs. AWS Korea Tech Blog.](https://aws.amazon.com/ko/blogs/tech/quickly-build-high-accuracy-generative-ai-applications-on-enterprise-data-using-amazon-kendra-langchain-and-large-language-models)
- **Daekeun Kim** (2023). [Build a powerful question answering bot with Amazon SageMaker, Amazon OpenSearch Service, Streamlit, and LangChain. AWS Korea Tech Blog.](https://aws.amazon.com/ko/blogs/tech/build-a-powerful-question-answering-bot-with-amazon-sagemaker-amazon-opensearch-service-streamlit-and-langchain)
- **Daekeun Kim** (2023). [Interactively fine-tune Falcon-40B and other LLMs on Amazon SageMaker Studio notebooks using QLoRA. AWS Korea Tech Blog.](https://aws.amazon.com/ko/blogs/tech/interactively-fine-tune-falcon-40b-and-other-llms-on-amazon-sagemaker-studio-notebooks-using-qlora)
- **Daekeun Kim** (2023). [Deploy Falcon-40B with large model inference DLCs on Amazon SageMaker. AWS Korea Tech Blog.](https://aws.amazon.com/ko/blogs/tech/machine-learning-deploy-falcon-40b-with-large-model-inference-dlcs-on-amazon-sagemaker)
- Hyundoo Jin, **Daekeun Kim**, Daeyeol Shim, and Daehoon Oh (2023). [Using Amazon SageMaker Distributed Training with KakaoStyle to Model a Category Automated Classification System. AWS Korea Tech Blog.](https://aws.amazon.com/ko/blogs/tech/amazon-sagemaker-distributed-training-for-automated-category-classification)
- **Daekeun Kim** and Hyeonsang Jeon (2023). [Train a Large Language Model on a single Amazon SageMaker GPU with Hugging Face and LoRA. AWS Korea Tech Blog.](https://aws.amazon.com/ko/blogs/tech/train-a-large-language-model-on-a-single-amazon-sagemaker-gpu-with-hugging-face-and-lora)
- Sungwon Han, Heewon Ko, Hyojung Kang, Kyungdae Cho, Sanghwa Na, and **Daekeun Kim** (2023). [SK Telecom's Case Study of Building a ML Pipeline Using AWS Inferentia and AWS Step Functions. AWS Korea Tech Blog.](https://aws.amazon.com/ko/blogs/tech/skt-mlops-using-aws-inferentia-stepfunctions/)

## üìï Tech book Translation
- **Daekeun Kim** and Daeyeol Shim (2023). Co-translated ‚Äú[Machine Learning System Engineering in Action](https://product.kyobobook.co.kr/detail/S000211556863)‚Äù, authored by Ben Wilson.
- **Daekeun Kim** and Youngmin Kim (2023). Co-translated ‚Äú[Designing Machine Learning System](https://product.kyobobook.co.kr/detail/S000201212403)‚Äù, authored by Chip Huyen.

---
